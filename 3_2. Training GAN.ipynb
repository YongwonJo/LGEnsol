{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683bf0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d66fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGANDataset(Dataset):\n",
    "    def __init__(self, \n",
    "        transform = transforms.Compose([\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=(0.5),\n",
    "                                                        std=(0.5,))\n",
    "                                ])):\n",
    "\n",
    "        self.root_dir = os.getcwd()\n",
    "        self.data_dir = os.path.join(self.root_dir, 'mnist', 'data')\n",
    "        self.transform = transform\n",
    "\n",
    "        self.imgs = [os.path.join(self.data_dir, pth) for pth in os.listdir(self.data_dir)]\n",
    "        # self.imgs = self.imgs[:500]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_pth = self.imgs[index]\n",
    "\n",
    "        img = np.load(img_pth)\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06321f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        return torch.tanh(self.fc4(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c15d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        return torch.sigmoid(self.fc4(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dabf470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 잡기\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c3007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset, DataLoader 정의\n",
    "# batch_size 설정 & epoch 정의\n",
    "dataset = CustomGANDataset()\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c73e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model hyperparameter-Generator\n",
    "g_input_dim = 100\n",
    "g_hidden_dim = 256\n",
    "g_output_dim = 784 # 28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda0e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model hyperparameter-Discriminator\n",
    "d_input_dim = g_output_dim\n",
    "d_hidden_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbb21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "G = Generator(g_input_dim, g_hidden_dim, g_output_dim)\n",
    "G = G.to(device=device)\n",
    "D = Discriminator(d_input_dim, d_hidden_dim)\n",
    "D = D.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad56a5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목적함수 설정\n",
    "criterion = nn.BCELoss()\n",
    "criterion = criterion.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer 설정\n",
    "optimizer_g = optim.Adam(G.parameters(), lr=0.0002)\n",
    "optimizer_d = optim.Adam(D.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f22da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save directory 설정\n",
    "root_dir = os.getcwd()\n",
    "data_dir = os.path.join(root_dir, 'mnist')\n",
    "gan_dir = os.path.join(data_dir, 'GAN')\n",
    "os.makedirs(gan_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef99b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "total_step = len(train_loader)\n",
    "cnt = 0\n",
    "g_losses, d_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with tqdm(total=len(train_loader)) as tbar:\n",
    "        for idx, imgs in enumerate(train_loader):\n",
    "            N, _, _, _ = imgs.size()\n",
    "\n",
    "            imgs = imgs.to(device=device)\n",
    "            imgs = imgs.view(N, -1)\n",
    "\n",
    "            label_real = torch.ones(N, 1).to(device=device)\n",
    "            label_fake = torch.zeros(N, 1).to(device=device)\n",
    "            \n",
    "            # training discriminator\n",
    "            optimizer_d.zero_grad()\n",
    "            output_real = D(imgs)\n",
    "\n",
    "            d_loss_real = criterion(output_real, label_real)\n",
    "            score_real = output_real\n",
    "\n",
    "            z = torch.randn(N, g_input_dim).to(device=device)\n",
    "            fake_imgs = G(z) # Images from Generator\n",
    "            output_fake = D(fake_imgs)\n",
    "            d_loss_fake = criterion(output_fake, label_fake)\n",
    "            score_fake = output_fake\n",
    "\n",
    "            # backpropagation\n",
    "            d_loss_total = d_loss_fake+d_loss_real  \n",
    "            d_loss_total.backward()\n",
    "            optimizer_d.step()\n",
    "            \n",
    "            if cnt % 50 == 0:\n",
    "                d_losses.append(d_loss_total.item())\n",
    "            \n",
    "            # training generator\n",
    "            optimizer_g.zero_grad()\n",
    "            z = torch.randn(N, g_input_dim).to(device=device)\n",
    "            fake_imgs = G(z)\n",
    "\n",
    "            output_fake = D(fake_imgs)\n",
    "\n",
    "            g_loss = criterion(output_fake, label_real)\n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_g.step()\n",
    "\n",
    "            if cnt % 50 == 0:\n",
    "                g_losses.append(g_loss.item())\n",
    "\n",
    "            tbar.set_description('Epoch [{:3d}/{:3d}], Step [{:2d}/{:2d}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}'\n",
    "                  .format(epoch, epochs, idx + 1, total_step, d_loss_total.item(), g_loss.item(),\n",
    "                          score_real.mean().item(), score_fake.mean().item()))\n",
    "            cnt += 1\n",
    "            \n",
    "            if cnt % 100 == 0:\n",
    "                torch.save(G.state_dict(), os.path.join(gan_dir, f'generator_{str(cnt)}.pth'))\n",
    "                torch.save(D.state_dict(), os.path.join(gan_dir, f'discriminator_{str(cnt)}.pth'))\n",
    "                \n",
    "                plt.plot(range(len(d_losses)), d_losses, label='Discriminator loss', c='red')\n",
    "                plt.plot(range(len(g_losses)), g_losses, label='Discriminator loss', c='blue')\n",
    "                plt.legend()\n",
    "                plt.savefig(os.path.join(data_dir, f'loss plot.png'))\n",
    "                plt.close()\n",
    "\n",
    "            tbar.update(1)\n",
    "        \n",
    "        imgs = imgs.reshape(N, 1, 28, 28)\n",
    "        save_image(imgs, os.path.join(gan_dir, f\"imgs_{str(epoch)}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e75eb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
