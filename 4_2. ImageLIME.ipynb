{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21e8465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib import request\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16677be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지출처: https://www.green-dog.com/cocokara/issho-ni-motto/about-the-wisdom-of-a-dog-230/\n",
    "url = 'https://www.green-dog.com/cocokara/wp/wp-content/uploads/7564-00230_3.jpg'        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36996d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()\n",
    "data_dir = os.path.join(root_dir, 'data')\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0b1c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fname = os.path.join(data_dir, 'dogs.jpg')\n",
    "request.urlretrieve(url, save_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873f3dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(save_fname).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ad1438",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2112f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Transform(object):\n",
    "    def __init__(self):\n",
    "        self.transform_shape = self.get_pil_transform()\n",
    "        self.transform_tensor = self.get_preprocess_transform()\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_pil_transform(): \n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.CenterCrop(224)\n",
    "        ])    \n",
    "        return transform   \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_preprocess_transform():\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                        std=[0.229, 0.224, 0.225])     \n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])    \n",
    "        return transform\n",
    "    \n",
    "    @staticmethod\n",
    "    def transform_unsqueeze(img):\n",
    "        transform = get_input_transform()\n",
    "        # unsqeeze converts single image to batch of 1\n",
    "        return transform(img).unsqueeze(0)\n",
    "    \n",
    "img_transform = Image_Transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bb676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3461b60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전학습된 모델 호출\n",
    "model = models.inception_v3(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a26ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet class index 다운로드 주소\n",
    "# https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
    "\n",
    "# JSON 파일 호출\n",
    "idx2label, cls2label, cls2idx = [], {}, {}\n",
    "with open(file=os.path.abspath('./data/imagenet_class_index.json'), mode='rt') as read_file:\n",
    "    class_idx = json.load(read_file)\n",
    "    idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]\n",
    "    cls2label = {class_idx[str(k)][0]: class_idx[str(k)][1] for k in range(len(class_idx))}\n",
    "    cls2idx = {class_idx[str(k)][0]: k for k in range(len(class_idx))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f869ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러온 이미지를 텐서 형태로 만든다\n",
    "img_t = sample_transform(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e55e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전학습된 모델을 검증 모드로 바꾼다\n",
    "# Dropout 제거 및 BatchNorm의 파라미터 고정 \n",
    "model.eval()\n",
    "\n",
    "# 이미지로부터 예측된 각 클래스 별 로짓 값을 산출\n",
    "logits = model(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96034097",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25730915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 로짓 값을 0~1 사이의 확률값으로 변환\n",
    "probs = F.softmax(logits, dim=1)\n",
    "\n",
    "# 그 중 확률값이 가장 높은 5개를 반환\n",
    "probs5 = probs.topk(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69733645",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b3af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반환된 5개의 클래스 별 확률값 및 인덱스/인덱스명 시각화\n",
    "array_prob = probs5[0][0].detach().numpy()\n",
    "array_class = probs5[1][0].detach().numpy()\n",
    "col = ['Probability', 'Index_number', 'Index_name']\n",
    "pd.DataFrame(tuple((p,c, idx2label[c]) for p, c in zip(array_prob, array_class)), columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0bb5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측한 클래스 인덱스 값 반환 (최대 로짓을 가지는 클래스의 인덱스 값 반환)\n",
    "def batch_predict(images):\n",
    "    model.eval()\n",
    "    batch = torch.stack(tuple(img_transform.transform_tensor(i) for i in images), dim=0)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    batch = batch.to(device)\n",
    "    \n",
    "    logits = model(batch)\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    return probs.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d52793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력할 이미지를 리스트 배열 안에 넣는다\n",
    "img_lst = [img_transform.transform_shape(img)]\n",
    "\n",
    "test_pred = batch_predict(img_lst)\n",
    "test_pred.squeeze().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72548a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shaped = img_transform.transform_shape(img)\n",
    "\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "explanation = explainer.explain_instance(np.array(img_shaped), \n",
    "                                         batch_predict, # classification function >> batch_predict\n",
    "                                         top_labels=5, \n",
    "                                         hide_color=0, \n",
    "                                         num_samples=1000) # size of the neighborhood to learn the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86a9295",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\n",
    "img_boundry1 = mark_boundaries(temp/255.0, mask)\n",
    "plt.imshow(img_boundry1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07230020",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n",
    "img_boundry2 = mark_boundaries(temp/255.0, mask)\n",
    "plt.imshow(img_boundry2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
